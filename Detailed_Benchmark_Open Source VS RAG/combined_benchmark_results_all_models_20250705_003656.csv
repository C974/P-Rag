File_Name,Model_Name,Embedding_Model,Total_Questions,Correct_Answers,Wrong_Answers,Overall_Accuracy,Remember_Total_Questions,Remember_Correct_Answers,Remember_Wrong_Answers,Remember_Accuracy,Understand_Total_Questions,Understand_Correct_Answers,Understand_Wrong_Answers,Understand_Accuracy,Apply_Total_Questions,Apply_Correct_Answers,Apply_Wrong_Answers,Apply_Accuracy,Analyze_Total_Questions,Analyze_Correct_Answers,Analyze_Wrong_Answers,Analyze_Accuracy,Evaluate_Total_Questions,Evaluate_Correct_Answers,Evaluate_Wrong_Answers,Evaluate_Accuracy,Create_Total_Questions,Create_Correct_Answers,Create_Wrong_Answers,Create_Accuracy
benchmark_results_20250704_234656.json,Qwen/Qwen3-4B,intfloat/e5-large-v2,222,205,17,0.9234234234234234,40,38,2,0.95,40,40,0,1.0,40,40,0,1.0,40,38,2,0.95,40,31,9,0.775,22,18,4,0.8181818181818182
benchmark_results_20250704_171514.json,Qwen/Qwen3-1.7B,intfloat/e5-large-v2,222,201,21,0.9054054054054054,40,37,3,0.925,40,37,3,0.925,40,39,1,0.975,40,38,2,0.95,40,33,7,0.825,22,17,5,0.7727272727272727
benchmark_results_20250704_231403.json,Qwen/Qwen3-1.7B,BAAI/bge-large-en-v1.5,222,199,23,0.8963963963963963,40,33,7,0.825,40,37,3,0.925,40,40,0,1.0,40,38,2,0.95,40,32,8,0.8,22,19,3,0.8636363636363636
benchmark_results_20250704_213307.json,deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B,intfloat/e5-large-v2,222,163,59,0.7342342342342343,40,26,14,0.65,40,30,10,0.75,40,31,9,0.775,40,34,6,0.85,40,28,12,0.7,22,14,8,0.6363636363636364
benchmark_results_20250704_222249.json,meta-llama/Llama-3.2-3B-Instruct,intfloat/e5-large-v2,222,137,85,0.6171171171171171,40,15,25,0.375,40,33,7,0.825,40,30,10,0.75,40,21,19,0.525,40,27,13,0.675,22,11,11,0.5
benchmark_results_20250704_184424.json,microsoft/Phi-4-mini-reasoning,intfloat/e5-large-v2,222,109,113,0.49099099099099097,40,18,22,0.45,40,27,13,0.675,40,26,14,0.65,40,16,24,0.4,40,6,34,0.15,22,16,6,0.7272727272727273
detailed_benchmark_results_Fanar-1-9B-Instruct.json,Fanar-1-9B-Instruct,N/A,222,19,203,0.08558558558558559,40,11,29,0.275,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,3,37,0.075,22,5,17,0.22727272727272727
detailed_benchmark_results_Mistral-Small-24B-Instruct-2501.json,Mistral-Small-24B-Instruct-2501,N/A,222,17,205,0.07657657657657657,40,9,31,0.225,40,0,40,0.0,40,1,39,0.025,40,0,40,0.0,40,2,38,0.05,22,5,17,0.22727272727272727
detailed_benchmark_results_gemma-3-12b-it.json,gemma-3-12b-it,N/A,222,17,205,0.07657657657657657,40,9,31,0.225,40,0,40,0.0,40,1,39,0.025,40,0,40,0.0,40,4,36,0.1,22,3,19,0.13636363636363635
detailed_benchmark_results_granite-3.3-8b-instruct.json,granite-3.3-8b-instruct,N/A,222,17,205,0.07657657657657657,40,9,31,0.225,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,4,36,0.1,22,4,18,0.18181818181818182
detailed_benchmark_results_Mistral-7B-Instruct-v0.3.json,Mistral-7B-Instruct-v0.3,N/A,222,16,206,0.07207207207207207,40,9,31,0.225,40,0,40,0.0,40,1,39,0.025,40,0,40,0.0,40,3,37,0.075,22,3,19,0.13636363636363635
detailed_benchmark_results_Qwen3-14B.json,Qwen3-14B,N/A,222,15,207,0.06756756756756757,40,7,33,0.175,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,3,37,0.075,22,5,17,0.22727272727272727
detailed_benchmark_results_Meta-Llama-3-8B-Instruct.json,Meta-Llama-3-8B-Instruct,N/A,222,14,208,0.06306306306306306,40,9,31,0.225,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,3,37,0.075,22,2,20,0.09090909090909091
detailed_benchmark_results_Phi-3.5-MoE-instruct.json,Phi-3.5-MoE-instruct,N/A,222,13,209,0.05855855855855856,40,8,32,0.2,40,1,39,0.025,40,0,40,0.0,40,0,40,0.0,40,2,38,0.05,22,2,20,0.09090909090909091
detailed_benchmark_results_gemma-3-4b-it.json,gemma-3-4b-it,N/A,222,11,211,0.04954954954954955,40,4,36,0.1,40,0,40,0.0,40,1,39,0.025,40,0,40,0.0,40,2,38,0.05,22,4,18,0.18181818181818182
detailed_benchmark_results_Phi-4-mini-instruct.json,Phi-4-mini-instruct,N/A,222,11,211,0.04954954954954955,40,5,35,0.125,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,2,38,0.05,22,4,18,0.18181818181818182
detailed_benchmark_results_Phi-4-mini-reasoning.json,Phi-4-mini-reasoning,N/A,222,10,212,0.04504504504504504,40,3,37,0.075,40,0,40,0.0,40,1,39,0.025,40,0,40,0.0,40,3,37,0.075,22,3,19,0.13636363636363635
detailed_benchmark_results_falcon-11B.json,falcon-11B,N/A,222,10,212,0.04504504504504504,40,6,34,0.15,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,2,38,0.05,22,2,20,0.09090909090909091
detailed_benchmark_results_falcon-7b-instruct.json,falcon-7b-instruct,N/A,222,9,213,0.04054054054054054,40,3,37,0.075,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,3,37,0.075,22,3,19,0.13636363636363635
detailed_benchmark_results_DeepSeek-R1-Distill-Llama-8B.json,DeepSeek-R1-Distill-Llama-8B,N/A,222,8,214,0.036036036036036036,40,5,35,0.125,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,1,39,0.025,22,2,20,0.09090909090909091
detailed_benchmark_results_DeepSeek-R1-Distill-Qwen-32B.json,DeepSeek-R1-Distill-Qwen-32B,N/A,222,8,214,0.036036036036036036,40,5,35,0.125,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,1,39,0.025,22,2,20,0.09090909090909091
detailed_benchmark_results_Qwen3-1.7B.json,Qwen3-1.7B,N/A,222,7,215,0.03153153153153153,40,2,38,0.05,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,2,38,0.05,22,3,19,0.13636363636363635
detailed_benchmark_results_Llama-3.2-1B.json,Llama-3.2-1B,N/A,222,5,217,0.02252252252252252,40,3,37,0.075,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,1,39,0.025,22,1,21,0.045454545454545456
detailed_benchmark_results_gemma-3-1b-it_palestine.json,gemma-3-1b-it_palestine,N/A,222,5,217,0.02252252252252252,40,1,39,0.025,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,2,38,0.05,22,2,20,0.09090909090909091
detailed_benchmark_results_DeepSeek-R1-Distill-Qwen-1.5B.json,DeepSeek-R1-Distill-Qwen-1.5B,N/A,222,3,219,0.013513513513513514,40,1,39,0.025,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,1,39,0.025,22,1,21,0.045454545454545456
detailed_benchmark_Qwen1.5-0.5B.json,Qwen1.5-0.5B,N/A,222,3,219,0.013513513513513514,40,1,39,0.025,40,0,40,0.0,40,0,40,0.0,40,0,40,0.0,40,1,39,0.025,22,1,21,0.045454545454545456
