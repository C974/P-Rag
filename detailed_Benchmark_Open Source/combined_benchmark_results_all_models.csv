Model,Overall_Total,Overall_Correct,Overall_Accuracy,Remember_Total,Remember_Correct,Remember_Accuracy,Understand_Total,Understand_Correct,Understand_Accuracy,Apply_Total,Apply_Correct,Apply_Accuracy,Analyze_Total,Analyze_Correct,Analyze_Accuracy,Evaluate_Total,Evaluate_Correct,Evaluate_Accuracy,Create_Total,Create_Correct,Create_Accuracy
Fanar-1-9B-Instruct,222,19,8.558558558558559,40,11,27.500000000000004,40,0,0.0,40,0,0.0,40,0,0.0,40,3,7.5,22,5,22.727272727272727
Mistral-Small-24B-Instruct-2501,222,17,7.657657657657657,40,9,22.5,40,0,0.0,40,1,2.5,40,0,0.0,40,2,5.0,22,5,22.727272727272727
gemma-3-12b-it,222,17,7.657657657657657,40,9,22.5,40,0,0.0,40,1,2.5,40,0,0.0,40,4,10.0,22,3,13.636363636363635
granite-3.3-8b-instruct,222,17,7.657657657657657,40,9,22.5,40,0,0.0,40,0,0.0,40,0,0.0,40,4,10.0,22,4,18.181818181818183
Mistral-7B-Instruct-v0.3,222,16,7.207207207207207,40,9,22.5,40,0,0.0,40,1,2.5,40,0,0.0,40,3,7.5,22,3,13.636363636363635
Qwen3-14B,222,15,6.756756756756757,40,7,17.5,40,0,0.0,40,0,0.0,40,0,0.0,40,3,7.5,22,5,22.727272727272727
Meta-Llama-3-8B-Instruct,222,14,6.306306306306306,40,9,22.5,40,0,0.0,40,0,0.0,40,0,0.0,40,3,7.5,22,2,9.090909090909092
Phi-3.5-MoE-instruct,222,13,5.8558558558558556,40,8,20.0,40,1,2.5,40,0,0.0,40,0,0.0,40,2,5.0,22,2,9.090909090909092
gemma-3-4b-it,222,11,4.954954954954955,40,4,10.0,40,0,0.0,40,1,2.5,40,0,0.0,40,2,5.0,22,4,18.181818181818183
Phi-4-mini-instruct,222,11,4.954954954954955,40,5,12.5,40,0,0.0,40,0,0.0,40,0,0.0,40,2,5.0,22,4,18.181818181818183
Phi-4-mini-reasoning,222,10,4.504504504504505,40,3,7.5,40,0,0.0,40,1,2.5,40,0,0.0,40,3,7.5,22,3,13.636363636363635
falcon-11B,222,10,4.504504504504505,40,6,15.0,40,0,0.0,40,0,0.0,40,0,0.0,40,2,5.0,22,2,9.090909090909092
falcon-7b-instruct,222,9,4.054054054054054,40,3,7.5,40,0,0.0,40,0,0.0,40,0,0.0,40,3,7.5,22,3,13.636363636363635
DeepSeek-R1-Distill-Llama-8B,222,8,3.6036036036036037,40,5,12.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,2,9.090909090909092
DeepSeek-R1-Distill-Qwen-32B,222,8,3.6036036036036037,40,5,12.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,2,9.090909090909092
Qwen3-1.7B,222,7,3.153153153153153,40,2,5.0,40,0,0.0,40,0,0.0,40,0,0.0,40,2,5.0,22,3,13.636363636363635
Llama-3.2-1B,222,5,2.2522522522522523,40,3,7.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,1,4.545454545454546
gemma-3-1b-it,222,5,2.2522522522522523,40,1,2.5,40,0,0.0,40,0,0.0,40,0,0.0,40,2,5.0,22,2,9.090909090909092
DeepSeek-R1-Distill-Qwen-1.5B,222,3,1.3513513513513513,40,1,2.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,1,4.545454545454546
detailed_benchmark_Qwen1.5-0.5B,222,3,1.3513513513513513,40,1,2.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,1,4.545454545454546
